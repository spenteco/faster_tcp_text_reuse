{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess EEBO-TCP\n",
    "\n",
    "This notebook turns all of EEBP-TCP (60,300 files) into pickled representations of those files useful for matching.\n",
    "\n",
    "The logic for processing one file is in function preprocess_one_file in file matching_functions.py.  Because so much logic is offloaded to matching_functions.py, this process looks simpler than it really is.\n",
    "\n",
    "Furthermore, because most of the logic is in matching_functions.py, this notebook is really just a process for queueing up files to be processed, and for starting multiple workers to process the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, glob, os, json\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from matching_functions import *\n",
    "from test_ids import *\n",
    "\n",
    "INPUT_FOLDER = '/home/spenteco/0/eebo_adorned/'\n",
    "OUTPUT_FOLDER = '/home/spenteco/0/eebo_shingled/'\n",
    "TEMP_FOLDER = '/home/spenteco/0/temp/'\n",
    "SHINGLE_LENGTH = 3\n",
    "NUM_WORKER_THREADS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Worker\n",
    "\n",
    "A worker reads a task from the queue, parses it, and then calls code in matching_functions.py, where the actually processing occurs.  When it's done, it marks the task ask done, and then gets the next task.  And so on, until the queue is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingle_worker(worker_number):\n",
    "    \n",
    "    while not q.empty():\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        body = q.get()\n",
    "        \n",
    "        PATH_TO_INPUT_FILE = body.split('|')[0]\n",
    "        OUTPUT_FOLDER = body.split('|')[1]\n",
    "        SHINGLE_LENGTH = int(body.split('|')[2])\n",
    "        TCP_ID = PATH_TO_INPUT_FILE.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        result_message = None\n",
    "        \n",
    "        if os.path.isfile(OUTPUT_FOLDER + TCP_ID + '.pickle'):\n",
    "            pass\n",
    "        else:\n",
    "            \n",
    "            try:\n",
    "    \n",
    "                file_data = preprocess_one_file(PATH_TO_INPUT_FILE, SHINGLE_LENGTH)\n",
    "\n",
    "                f = open(OUTPUT_FOLDER + TCP_ID + '.pickle', 'wb')\n",
    "                pickle.dump(file_data, f)\n",
    "                f.close()\n",
    "                \n",
    "                stop_time = time.time()\n",
    "                    \n",
    "            except etree.XMLSyntaxError:\n",
    "                result_message = 'ERROR XMLSyntaxError ' + PATH_TO_INPUT_FILE\n",
    "        \n",
    "        q.task_done()\n",
    "        \n",
    "        if result_message != None:\n",
    "            print(result_message + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up the Queue\n",
    "\n",
    "One item per EEBO-TCP file.  And item is the same as one task for a worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue()\n",
    "json.dump\n",
    "for path_to_file in glob.glob(INPUT_FOLDER + '*.xml'):\n",
    "\n",
    "    #tcp_id = path_to_file.split('/')[-1].split('.')[0]\n",
    "    #if tcp_id not in test_ids:\n",
    "    #    continue\n",
    "    \n",
    "    q.put(path_to_file + '|' + OUTPUT_FOLDER + '|' + str(SHINGLE_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a bunch of workers\n",
    "\n",
    "I've been starting 6 on my fairly generic Dell workstation.  These can process EEBO-TCP in about four hours.\n",
    "\n",
    "The workers seem to be limited by the speed of the local disk.  I expect I could get it to run faster if I put the files on an SSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14441.589958429337\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "    \n",
    "for a in range(NUM_WORKER_THREADS):\n",
    "    t = Thread(target=shingle_worker, args=(a,))\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "q.join()\n",
    "\n",
    "print('time:', (time.time() - start_time))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sqlite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_shingle_worker(worker_number):\n",
    "    \n",
    "    out_f = open(TEMP_FOLDER + 'shingle_data.' + str(worker_number) + '.txt', 'w', encoding='utf-8')\n",
    "    \n",
    "    while not q.empty():\n",
    "        \n",
    "        body = q.get()\n",
    "        \n",
    "        PATH_TO_INPUT_FILE = body\n",
    "        TCP_ID = PATH_TO_INPUT_FILE.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            data = load_pickle_file(PATH_TO_INPUT_FILE)\n",
    "            \n",
    "            for s, i in data['shingles'].items():\n",
    "                out_f.write(s + '\\t' + TCP_ID + '\\t' + json.dumps(i) + '\\n')\n",
    "            \n",
    "        except EOFError:\n",
    "            pass\n",
    "        \n",
    "        q.task_done()\n",
    "            \n",
    "    out_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue()\n",
    "\n",
    "for path_to_file in glob.glob(OUTPUT_FOLDER + '*.pickle'):\n",
    "    q.put(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4598.9048981666565\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "    \n",
    "for a in range(NUM_WORKER_THREADS):\n",
    "    t = Thread(target=dump_shingle_worker, args=(a,))\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "q.join()\n",
    "dump_shingle_worker\n",
    "print('time:', (time.time() - start_time))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"CREATE TABLE shingles (shingle TEXT NOT NULL, tcp_id TEXT NOT NULL, offsets TEXT NOT NULL);\n",
    ".separator \"\\t\"\n",
    ".import /home/spenteco/0/temp/shingle_data.0.txt shingles\n",
    ".import /home/spenteco/0/temp/shingle_data.1.txt shingles\n",
    ".import /home/spenteco/0/temp/shingle_data.2.txt shingles\n",
    ".import /home/spenteco/0/temp/shingle_data.3.txt shingles\n",
    ".import /home/spenteco/0/temp/shingle_data.4.txt shingles\n",
    ".import /home/spenteco/0/temp/shingle_data.5.txt shingles\n",
    "CREATE INDEX shingles_0 ON shingles(shingle);\n",
    "CREATE INDEX shingles_1 ON shingles(tcp_id);\n",
    "CREATE INDEX shingles_2 ON shingles(tcp_id, shingle);\n",
    "\"\"\"\n",
    "\n",
    "f = open('create_database.sql', 'w')\n",
    "f.write(sql + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 spenteco spenteco 88033738752 Nov  1 11:01 /home/spenteco/0/temp/shingles.sqlite3\r\n"
     ]
    }
   ],
   "source": [
    "!sqlite3 /home/spenteco/0/temp/shingles.sqlite3 < create_database.sql\n",
    "!ls -l /home/spenteco/0/temp/shingles.sqlite3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
